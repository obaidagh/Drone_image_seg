{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00f45fb9-a6bc-446e-b050-546e6d83dc6a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <center style=\"background-color:#606F66;color: white; vertical-align: middle; padding:20px 5px;\">Aerial Semantic Segmentation Drone </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419d64fb-86a3-4cf6-ae6a-fee549e562ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <center style=\"background-color:#EF6145;color: white; vertical-align: middle; padding:10px 5px;\">Importing Libraries</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "from RGB_Mask import RGB_to_Mask\n",
    "from Augmentaion_Pipeline import  image_augmentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deec3b7-0225-4d10-89a8-947a893d3713",
   "metadata": {},
   "source": [
    "# <center style=\"background-color:#54A57C;color: white; vertical-align: middle; padding:10px 5px;\">Preprocessing</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMG properties\n",
    "IMG_HEIGHT = 800\n",
    "IMG_WIDTH  = 1200\n",
    "IMG_CHANNELS = 3\n",
    "Num_Classes = 23\n",
    "reshape_dims = (IMG_HEIGHT,IMG_WIDTH)\n",
    "combined=[Num_Classes,reshape_dims]# to pass as argument for map function\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center style=\"background-color:#EF6145;color: white; vertical-align: middle; padding:10px 5px;\">Image Path glob</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9aa28c1f-6666-40ae-be70-330c97b43bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mask related paths\n",
    "RGB_Mask_PNG_LIST = tf.io.gfile.glob(\"../Data/RGB_color_image_masks/*.png\")\n",
    "RGB_Mask_PNG_LIST.sort()\n",
    "\n",
    "RGB_to_mask_path = '../Data/Mask'\n",
    "Mask_aug_path    = '../Data/Mask_Augmented'\n",
    "\n",
    "#orginal Re;lated paths\n",
    "ORIGINAL_JPG_LIST = tf.io.gfile.glob('../Data/original_images/*.jpg')\n",
    "ORIGINAL_JPG_LIST.sort()\n",
    "Orginal_aug_path = '../Data/Orginal_Augmented'\n",
    "\n",
    "read_csv = pd.read_csv('../Data/class_dict_seg.csv',index_col=False,skipinitialspace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center style=\"background-color:#EF6145;color: white; vertical-align: middle; padding:10px 5px;\">RGB to Mask</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_to_Mask(read_csv,RGB_Mask_PNG_LIST,RGB_to_mask_path) #only one time run\n",
    "Mask_PNG_LIST = tf.io.gfile.glob(\"../Data/Mask/*.png\")\n",
    "Mask_PNG_LIST.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center style=\"background-color:#EF6145;color: white; vertical-align: middle; padding:10px 5px;\">Augmentaion</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_90 = augmenters.Rot90(1,keep_size=False) #rot_90 = augmenters.Rot90(times) #time=1 =>90deg, time=2 =>180deg, time=3 =>270deg\n",
    "rot_180 = augmenters.Rot90(2,keep_size=False) \n",
    "rot_270 = augmenters.Rot90(3,keep_size=False)\n",
    "flip_hor = augmenters.Fliplr(1) \n",
    "fli_vert = augmenters.Flipud(1)\n",
    "\n",
    "pipeline = [rot_90, rot_180, rot_270, flip_hor, fli_vert]\n",
    "\n",
    "\n",
    "#image_augmentation(ORIGINAL_JPG_LIST,Orginal_aug_path,pipeline)#orginal augmentaion\n",
    "image_augmentation(Mask_PNG_LIST,Mask_aug_path,pipeline)#mask augmentaion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ORIGINAL_JPG_LIST_with_aug = ORIGINAL_JPG_LIST+tf.io.gfile.glob('./Data/Orginal_Augmented/*.jpg')\n",
    "Mask_PNG_LIST_with_aug      = Mask_PNG_LIST+tf.io.gfile.glob('./Data/Mask_Augmented/*.png')\n",
    "\n",
    "\n",
    "index= [os.path.splitext(filename)[0] for filename in os.listdir('./Data/original_images/')]\n",
    "index_with_aug=index+[os.path.splitext(filename)[0] for filename in os.listdir('./Data/Orginal_Augmented/')]\n",
    "\n",
    "ORIGINAL_JPG_LIST_with_aug.sort()\n",
    "Mask_PNG_LIST_with_aug.sort()\n",
    "index_with_aug.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center style=\"background-color:#EF6145;color: white; vertical-align: middle; padding:10px 5px;\">Creating Dataframe from paths</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91961b0d-5a01-459e-a114-923a0f1c357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame((index_with_aug,ORIGINAL_JPG_LIST_with_aug,Mask_PNG_LIST_with_aug)).T\n",
    "df.rename(columns={\n",
    "    0: 'index',\n",
    "    1: 'Orginal',\n",
    "    2: 'Segmented'},\n",
    "          inplace=True)\n",
    "df.set_index('index', inplace= True)\n",
    "df.to_csv('DataFrame.csv')\n",
    "\n",
    "df = shuffle(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaab3c6e-8a4b-49b1-a5ee-fb734680d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val = train_test_split(df, test_size=0.2, random_state=42)\n",
    "X_val,X_test = train_test_split(X_val, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center style=\"background-color:#EF6145;color: white; vertical-align: middle; padding:10px 5px;\">Convert dataframe to tensorflow BatchDataset</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-15 07:33:40.813593: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-06-15 07:33:40.813645: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (UB): /proc/driver/nvidia/version does not exist\n",
      "2022-06-15 07:33:40.815369: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "Train_DF= (tf.data.Dataset.from_tensor_slices((X_train['Orginal'].values,X_train['Segmented'].values)))\n",
    "\n",
    "Eval_DF = (tf.data.Dataset.from_tensor_slices((X_val['Orginal'].values,X_val['Segmented'].values)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185a0842-cccf-48a6-9122-0322734700bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_BatchDataset = (Train_DF.map(partial(decode_csv, combined))).batch(batch_size)\n",
    "Eval_BatchDataset  = (Eval_DF.map(partial(decode_csv, combined))).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br><br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code to save\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H=1\n",
    "\n",
    "original_img=Image.open(ORIGINAL_JPG_LIST[H])\n",
    "original_img= np.array(original_img)\n",
    "mask_image = Image.open(Mask_PNG_LIST[H])\n",
    "mask_image = np.array(mask_image)\n",
    "\n",
    "orginal_aug=oh_shit(original_img,pipeline)\n",
    "mask_aug=oh_shit(mask_image,pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m = 3\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(25, 10), constrained_layout=True)\n",
    "\n",
    "axs[0].imshow(orginal_aug[m])\n",
    "axs[0].grid(False)\n",
    "\n",
    "\n",
    "axs[1].imshow(saved_loaded)\n",
    "axs[1].grid(False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36426ead222327eaf98b7ef020e60912101eb782bbe202ac201f9bb38ec1a105"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
